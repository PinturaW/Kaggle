{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7259c34c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-16T05:11:09.812281Z",
     "iopub.status.busy": "2025-08-16T05:11:09.811915Z",
     "iopub.status.idle": "2025-08-16T05:11:11.803841Z",
     "shell.execute_reply": "2025-08-16T05:11:11.802241Z"
    },
    "papermill": {
     "duration": 1.997259,
     "end_time": "2025-08-16T05:11:11.805921",
     "exception": false,
     "start_time": "2025-08-16T05:11:09.808662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fb3dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:11:11.812262Z",
     "iopub.status.busy": "2025-08-16T05:11:11.811688Z",
     "iopub.status.idle": "2025-08-16T05:11:15.602123Z",
     "shell.execute_reply": "2025-08-16T05:11:15.600720Z"
    },
    "papermill": {
     "duration": 3.795763,
     "end_time": "2025-08-16T05:11:15.603856",
     "exception": false,
     "start_time": "2025-08-16T05:11:11.808093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Titanic: Simple & Effective Approach\n",
      "Focus: Core patterns that work on Kaggle test set\n",
      "Train: (891, 12), Test: (418, 11)\n",
      "âœ… Using 13 core features\n",
      "\n",
      "ðŸ§ª Cross-validation results:\n",
      "CV Score: 0.8260 Â± 0.0071\n",
      "OOB Score: 0.8272\n",
      "\n",
      "ðŸ“Š Top Features:\n",
      "   feature  importance\n",
      "       Sex    0.260226\n",
      "     Title    0.259044\n",
      " Age*Class    0.109171\n",
      "      Fare    0.091551\n",
      "    Pclass    0.086935\n",
      "FamilySize    0.055635\n",
      "       Age    0.039990\n",
      "     SibSp    0.027842\n",
      "\n",
      "ðŸŽ¯ Submission created: simple_effective_submission.csv\n",
      "Survival rate: 36.6%\n",
      "\n",
      "ðŸ”„ Creating variant submissions...\n",
      "Variant 2: 37.8% survival rate\n",
      "Training survival rate: 38.4%\n",
      "Balanced: 36.6% survival rate\n",
      "Higher Recall: 39.2% survival rate\n",
      "Higher Precision: 33.0% survival rate\n",
      "\n",
      "ðŸš€ Created 5 submission variants!\n",
      "ðŸŽ¯ Recommended order:\n",
      "1. simple_effective_submission.csv\n",
      "2. simple_effective_v2.csv\n",
      "3. simple_effective_balanced.csv\n",
      "\n",
      "ðŸ’¡ This approach focuses on:\n",
      "- Minimal but proven feature engineering\n",
      "- Conservative Random Forest parameters\n",
      "- Features that generalize well to test set\n",
      "Expected Kaggle score: 78-80%+ ðŸŽ¯\n",
      "\n",
      "ðŸ“‹ Key Insights:\n",
      "- Most important features: Sex, Title, Fare, Age*Class\n",
      "- Family relationships matter (FamilySize, IsAlone)\n",
      "- Simple binning often works better than complex engineering\n",
      "- Conservative model parameters prevent overfitting\n"
     ]
    }
   ],
   "source": [
    "# Titanic Simple & Effective Solution\n",
    "# Based on proven high-scoring Kaggle approaches\n",
    "# Focus: Simplicity + Core patterns that work on test set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ðŸŽ¯ Titanic: Simple & Effective Approach\")\n",
    "print(\"Focus: Core patterns that work on Kaggle test set\")\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")\n",
    "\n",
    "def simple_but_effective_features(df):\n",
    "    \"\"\"\n",
    "    Minimal feature engineering based on proven Kaggle patterns\n",
    "    Only features that consistently work across train/test\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. Fill missing values (simple & robust)\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].median(), inplace=True) \n",
    "    data['Embarked'].fillna('S', inplace=True)\n",
    "    \n",
    "    # 2. Extract Title (most important engineered feature)\n",
    "    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Simplify titles to proven categories\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                          'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # 3. Family Size (proven predictor)\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['IsAlone'] = 0\n",
    "    data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "    # 4. Age*Class interaction (powerful for this dataset)\n",
    "    data['Age*Class'] = data['Age'] * data['Pclass']\n",
    "    \n",
    "    # 5. Simple Fare categories\n",
    "    data['FareBin'] = pd.qcut(data['Fare'], 4, labels=False)\n",
    "    \n",
    "    # 6. Simple Age categories  \n",
    "    data['AgeBin'] = pd.cut(data['Age'], 5, labels=False)\n",
    "    \n",
    "    # Convert categorical to numeric\n",
    "    data['Sex'] = data['Sex'].map({'female': 1, 'male': 0})\n",
    "    data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n",
    "    data['Title'] = data['Title'].map(title_mapping)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process data\n",
    "train_processed = simple_but_effective_features(train)\n",
    "test_processed = simple_but_effective_features(test)\n",
    "\n",
    "# Select features (only the most important ones)\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "           'Title', 'FamilySize', 'IsAlone', 'Age*Class', 'FareBin', 'AgeBin']\n",
    "\n",
    "X = train_processed[features]\n",
    "y = train_processed['Survived']\n",
    "X_test = test_processed[features]\n",
    "\n",
    "print(f\"âœ… Using {len(features)} core features\")\n",
    "\n",
    "# The Model: Random Forest with proven parameters for Titanic\n",
    "# These parameters are based on successful Kaggle submissions\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,      # Not too many (prevents overfitting)\n",
    "    max_depth=5,           # Shallow trees\n",
    "    min_samples_split=10,  # Conservative splitting  \n",
    "    min_samples_leaf=5,    # Conservative leaf size\n",
    "    max_features='auto',   # Let RF decide\n",
    "    random_state=42,\n",
    "    oob_score=True         # Out-of-bag score for validation\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "print(\"\\nðŸ§ª Cross-validation results:\")\n",
    "cv_scores = cross_val_score(rf, X, y, cv=StratifiedKFold(5, shuffle=True, random_state=42))\n",
    "print(f\"CV Score: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X, y)\n",
    "print(f\"OOB Score: {rf.oob_score_:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nðŸ“Š Top Features:\")\n",
    "print(feature_importance.head(8).to_string(index=False))\n",
    "\n",
    "# Generate predictions\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('simple_effective_submission.csv', index=False)\n",
    "\n",
    "survival_rate = predictions.mean()\n",
    "print(f\"\\nðŸŽ¯ Submission created: simple_effective_submission.csv\")\n",
    "print(f\"Survival rate: {survival_rate:.1%}\")\n",
    "\n",
    "# Additional submissions with slight variations\n",
    "print(f\"\\nðŸ”„ Creating variant submissions...\")\n",
    "\n",
    "# Variant 1: Slightly different RF parameters\n",
    "rf2 = RandomForestClassifier(\n",
    "    n_estimators=150, max_depth=4, min_samples_split=15, \n",
    "    min_samples_leaf=4, random_state=42\n",
    ")\n",
    "rf2.fit(X, y)\n",
    "pred2 = rf2.predict(X_test)\n",
    "\n",
    "submission2 = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': pred2\n",
    "})\n",
    "submission2.to_csv('simple_effective_v2.csv', index=False)\n",
    "print(f\"Variant 2: {pred2.mean():.1%} survival rate\")\n",
    "\n",
    "# Variant 3: Use predict_proba with custom threshold\n",
    "pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Try different thresholds based on training data analysis\n",
    "training_survival_rate = y.mean()\n",
    "print(f\"Training survival rate: {training_survival_rate:.1%}\")\n",
    "\n",
    "for threshold, name in [(0.5, 'balanced'), (0.45, 'higher_recall'), (0.55, 'higher_precision')]:\n",
    "    pred_thresh = (pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    submission_thresh = pd.DataFrame({\n",
    "        'PassengerId': test['PassengerId'],\n",
    "        'Survived': pred_thresh\n",
    "    })\n",
    "    \n",
    "    filename = f'simple_effective_{name}.csv'\n",
    "    submission_thresh.to_csv(filename, index=False)\n",
    "    print(f\"{name.replace('_', ' ').title()}: {pred_thresh.mean():.1%} survival rate\")\n",
    "\n",
    "print(f\"\\nðŸš€ Created 5 submission variants!\")\n",
    "print(f\"ðŸŽ¯ Recommended order:\")\n",
    "print(f\"1. simple_effective_submission.csv\")\n",
    "print(f\"2. simple_effective_v2.csv\") \n",
    "print(f\"3. simple_effective_balanced.csv\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ This approach focuses on:\")\n",
    "print(f\"- Minimal but proven feature engineering\")\n",
    "print(f\"- Conservative Random Forest parameters\") \n",
    "print(f\"- Features that generalize well to test set\")\n",
    "print(f\"Expected Kaggle score: 78-80%+ ðŸŽ¯\")\n",
    "\n",
    "# Quick analysis\n",
    "print(f\"\\nðŸ“‹ Key Insights:\")\n",
    "print(f\"- Most important features: Sex, Title, Fare, Age*Class\")\n",
    "print(f\"- Family relationships matter (FamilySize, IsAlone)\")\n",
    "print(f\"- Simple binning often works better than complex engineering\")\n",
    "print(f\"- Conservative model parameters prevent overfitting\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.432899,
   "end_time": "2025-08-16T05:11:16.325792",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-16T05:11:04.892893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
